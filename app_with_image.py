#!/usr/bin/env python3
"""
æ•°å­¦é¢˜ç›®è´¨é‡å®¡æ ¸ä¸åŸåˆ›åº¦æ£€æµ‹ç³»ç»Ÿ - å›¾ç‰‡è¯†åˆ«ç‰ˆ
æ”¯æŒæ–‡å­—è¾“å…¥å’Œå›¾ç‰‡ä¸Šä¼ ï¼ˆOCRè¯†åˆ«ï¼‰
"""
import streamlit as st
import json
import time
import os
import base64
from openai import OpenAI
from PIL import Image
import io

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="æ•°å­¦é¢˜ç›®å®¡æ ¸ç³»ç»Ÿ - å›¾ç‰‡è¯†åˆ«ç‰ˆ",
    page_icon="ğŸ”",
    layout="wide"
)

# API é…ç½®
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
DEEPSEEK_API_KEY = os.getenv("DEEPSEEK_API_KEY")
OPENAI_MODEL = os.getenv("OPENAI_MODEL", "gpt-5.1-chat-latest")
VISION_MODEL = "gpt-4o"  # ç”¨äºå›¾ç‰‡è¯†åˆ«
DEEPSEEK_MODEL = os.getenv("DEEPSEEK_MODEL", "deepseek-chat")

# æ£€æŸ¥é…ç½®
if not OPENAI_API_KEY:
    st.error("âŒ æœªé…ç½® OPENAI_API_KEY")
    st.stop()

if not DEEPSEEK_API_KEY:
    st.warning("âš ï¸ æœªé…ç½® DEEPSEEK_API_KEYï¼Œå°†åªä½¿ç”¨ GPT-5.1")
    DUAL_MODEL_ENABLED = False
else:
    DUAL_MODEL_ENABLED = True

# è´¨é‡å®¡æ ¸ Prompt
REVIEW_PROMPT_TEMPLATE = """You are an expert mathematics educator reviewing problem quality.

**IMPORTANT**: Do NOT attempt to solve the problem or verify if the answer is correct. Focus ONLY on evaluating the problem statement itself.

Evaluate this mathematical problem based on these 5 criteria:
1. **Clarity** (0-2 points): Is the problem statement clear, unambiguous, and easy to understand?
2. **Mathematical Rigor** (0-2 points): Are mathematical notations, symbols, and expressions used correctly and rigorously?
3. **Completeness** (0-2 points): Does the problem provide all necessary information? Are conditions sufficient to solve it?
4. **Solvability** (0-2 points): Does the problem appear to have a well-defined solution (unique or a clear solution set)?
5. **Educational Value** (0-2 points): Is this a meaningful mathematical problem worth studying?

**Problem to Review:**
{problem_text}

**Your Task:**
Evaluate the problem based on the 5 criteria above and respond in JSON format:

{{
  "clarity_score": 0-2,
  "rigor_score": 0-2,
  "completeness_score": 0-2,
  "solvability_score": 0-2,
  "educational_value_score": 0-2,
  "total_score": 0-10,
  "issues": ["list specific issues, if any"],
  "reasoning": "brief explanation of your evaluation",
  "recommendation": "ACCEPT (â‰¥7) / BORDERLINE (5-6) / REJECT (<5)"
}}

**Remember**: Focus on problem quality, NOT answer correctness!
"""

# åŸåˆ›åº¦æ£€æµ‹ Prompt
ORIGINALITY_PROMPT_TEMPLATE = """ä½ ç°åœ¨æ˜¯ä¸€åèµ„æ·±çš„å­¦æœ¯æŸ¥é‡ä¸“å®¶å’Œé«˜çº§æœç´¢å·¥ç¨‹ä¸“å®¶ã€‚

Task: è¯·é’ˆå¯¹æˆ‘æä¾›çš„é¢˜ç›®è¿›è¡Œæ·±åº¦åˆ†æï¼ŒæŸ¥éªŒè¯¥é¢˜ç›®çš„åŸåˆ›åº¦ï¼ˆæ˜¯å¦åœ¨ä½ çš„çŸ¥è¯†åº“ä¸­å­˜åœ¨åŸé¢˜æˆ–é«˜åº¦ç›¸ä¼¼çš„å˜ä½“ï¼‰ã€‚

**é‡è¦è¯´æ˜**ï¼š
- ä¸¥ç¦ç»™å‡ºä»»ä½•è§£é¢˜æ­¥éª¤æˆ–ç­”æ¡ˆ
- ä¸è¦å°è¯•è§£é¢˜
- åªåˆ†æé¢˜ç›®æœ¬èº«çš„åŸåˆ›æ€§

**æ£€ç´¢ç­–ç•¥ (Search Strategy)**:
1. å…³é”®è¯æŠ½æ ·ï¼šæå–é¢˜ç›®çš„æ ¸å¿ƒçŸ¥è¯†ç‚¹ã€ç½•è§æœ¯è¯­å’Œæ•°æ®ç»„åˆ
2. ç»“æ„åŒ–åŒ¹é…ï¼šå¿½ç•¥å…·ä½“çš„æ•°å€¼ï¼Œé‡ç‚¹å…³æ³¨é¢˜ç›®çš„é€»è¾‘ç»“æ„ã€è®¾å®šèƒŒæ™¯å’Œå·²çŸ¥æ¡ä»¶çš„ç»„åˆæ–¹å¼
3. å¤šå¹³å°è¦†ç›–ï¼šåœ¨ä½ çš„çŸ¥è¯†åº“ä¸­æ£€ç´¢åŒ…æ‹¬ä½†ä¸é™äºï¼š
   - ç»å…¸æ•™æï¼ˆå¦‚åŒæµé«˜ç­‰æ•°å­¦ã€æ™®æ—æ–¯é¡¿å¾®ç§¯åˆ†ç­‰ï¼‰
   - æ ‡å‡†é¢˜åº“ï¼ˆé«˜è€ƒçœŸé¢˜ã€è€ƒç ”çœŸé¢˜ã€AMCã€IMO ç­‰ï¼‰
   - çŸ¥åæ•™è‚²å¹³å°å’Œè®ºå›ï¼ˆAOPSã€çŸ¥ä¹ã€ç™¾åº¦æ•™è‚²ã€StackExchangeã€Chegg ç­‰ï¼‰
   - å­¦æœ¯è®ºæ–‡å’Œç«èµ›é¢˜åº“

**åˆ†æè¦æ±‚ (Analysis Requirements)**:
- ä¸ä»…è¦çœ‹è¯­ä¹‰å’Œæ•°å­—ï¼Œè¿˜è¦å…³æ³¨è§£é¢˜è·¯å¾„çš„ç›¸ä¼¼æ€§
- **å¦‚æœå‘ç°ç›¸ä¼¼é¢˜ç›®ï¼Œå¿…é¡»æä¾›å…·ä½“æ¥æºä¿¡æ¯**ï¼š
  - å¦‚æœæ¥è‡ªç½‘ç«™/è®ºå›ï¼Œæä¾›å®Œæ•´çš„URLé“¾æ¥
  - å¦‚æœæ¥è‡ªä¹¦ç±/è¯•å·ï¼Œæä¾›è¯¦ç»†å‡ºå¤„
  - å¦‚æœæ¥è‡ªç«èµ›ï¼Œæä¾›å¹´ä»½å’Œé¢˜å·
- åˆ†æé¢˜ç›®çš„ç‹¬ç‰¹ä¹‹å¤„

**é¢˜ç›®å†…å®¹**:
{problem_text}

**è¾“å‡ºæ ¼å¼ (Output Format)**:
è¯·ä»¥ JSON æ ¼å¼è¾“å‡ºï¼ŒåŒ…å«ä»¥ä¸‹å­—æ®µï¼š

{{
  "originality_conclusion": "åŸåˆ› / ç–‘ä¼¼æ¬è¿ / ç»“æ„é›·åŒ",
  "similar_problems": [
    {{
      "source": "æ¥æºåç§°",
      "source_url": "å…·ä½“é“¾æ¥æˆ–è¯¦ç»†å‡ºå¤„",
      "content": "ç›¸ä¼¼é¢˜ç›®çš„ç®€è¦æè¿°",
      "similarity_percentage": 85,
      "similarity_reason": "ç›¸ä¼¼ä¹‹å¤„çš„å…·ä½“è¯´æ˜"
    }}
  ],
  "unique_aspects": ["åˆ—å‡ºé¢˜ç›®çš„ç‹¬ç‰¹ä¹‹å¤„"],
  "keyword_analysis": "å…³é”®è¯å’Œæ ¸å¿ƒæ¦‚å¿µåˆ†æ",
  "structure_analysis": "é¢˜ç›®ç»“æ„å’Œé€»è¾‘æ¡†æ¶åˆ†æ",
  "overall_assessment": "æ•´ä½“è¯„ä¼°è¯´æ˜"
}}

**é‡è¦æé†’**: 
1. å¿…é¡»æä¾›å…·ä½“çš„æ¥æºé“¾æ¥æˆ–è¯¦ç»†å‡ºå¤„
2. ä¸è¦ç»™åŸåˆ›åº¦æ‰“åˆ†
3. ä¸¥ç¦åœ¨ä»»ä½•å­—æ®µä¸­åŒ…å«è§£é¢˜æ­¥éª¤æˆ–ç­”æ¡ˆï¼
"""

def encode_image_to_base64(image_file):
    """å°†ä¸Šä¼ çš„å›¾ç‰‡è½¬æ¢ä¸º base64"""
    image = Image.open(image_file)
    buffered = io.BytesIO()
    image.save(buffered, format="PNG")
    return base64.b64encode(buffered.getvalue()).decode('utf-8')

def extract_text_from_image(image_file):
    """ä½¿ç”¨ GPT-4 Vision ä»å›¾ç‰‡ä¸­æå–æ•°å­¦é¢˜ç›®"""
    try:
        client = OpenAI(api_key=OPENAI_API_KEY)
        
        # å°†å›¾ç‰‡è½¬æ¢ä¸º base64
        base64_image = encode_image_to_base64(image_file)
        
        response = client.chat.completions.create(
            model=VISION_MODEL,
            messages=[
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "text",
                            "text": """è¯·ä»”ç»†è¯†åˆ«å›¾ç‰‡ä¸­çš„æ•°å­¦é¢˜ç›®ã€‚

è¦æ±‚ï¼š
1. å‡†ç¡®è¯†åˆ«æ‰€æœ‰æ–‡å­—ã€æ•°å­¦ç¬¦å·ã€å…¬å¼
2. ä¿æŒåŸé¢˜ç›®çš„æ ¼å¼å’Œç»“æ„
3. å¦‚æœæœ‰å›¾è¡¨ï¼Œè¯·æè¿°å›¾è¡¨å†…å®¹
4. åªè¾“å‡ºé¢˜ç›®å†…å®¹ï¼Œä¸è¦æ·»åŠ ä»»ä½•è§£ç­”æˆ–è¯´æ˜

è¯·ç›´æ¥è¾“å‡ºè¯†åˆ«çš„é¢˜ç›®æ–‡å­—ï¼š"""
                        },
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/png;base64,{base64_image}"
                            }
                        }
                    ]
                }
            ],
            max_tokens=1000
        )
        
        return response.choices[0].message.content
    
    except Exception as e:
        return f"âŒ å›¾ç‰‡è¯†åˆ«å¤±è´¥: {str(e)}"

def call_openai_api(prompt, api_key, model, base_url="https://api.openai.com/v1"):
    """è°ƒç”¨ APIï¼ˆæ”¯æŒ OpenAI å’Œ DeepSeekï¼‰"""
    try:
        client = OpenAI(api_key=api_key, base_url=base_url)
        response = client.chat.completions.create(
            model=model,
            messages=[{"role": "user", "content": prompt}],
            response_format={"type": "json_object"}
        )
        return response.choices[0].message.content
    except Exception as e:
        return {"error": str(e)}

def get_recommendation_emoji(recommendation):
    """æ ¹æ®æ¨èç»“æœè¿”å›è¡¨æƒ…ç¬¦å·"""
    if "ACCEPT" in recommendation:
        return "âœ…"
    elif "BORDERLINE" in recommendation:
        return "âš ï¸"
    else:
        return "âŒ"

def get_originality_emoji(conclusion):
    """æ ¹æ®åŸåˆ›åº¦ç»“è®ºè¿”å›è¡¨æƒ…ç¬¦å·"""
    if "åŸåˆ›" in conclusion:
        return "âœ…"
    elif "ç»“æ„é›·åŒ" in conclusion:
        return "âš ï¸"
    else:
        return "âŒ"

# ä¸»ç•Œé¢
st.title("ğŸ” æ•°å­¦é¢˜ç›®å®¡æ ¸ç³»ç»Ÿ - å›¾ç‰‡è¯†åˆ«ç‰ˆ")
st.markdown("**æ”¯æŒæ–‡å­—è¾“å…¥ + å›¾ç‰‡ä¸Šä¼ ï¼ˆAIè¯†åˆ«ï¼‰**")
st.markdown("---")

# ä¾§è¾¹æ 
with st.sidebar:
    st.header("âš™ï¸ ç³»ç»Ÿé…ç½®")
    st.info(f"**GPTæ¨¡å‹**: {OPENAI_MODEL}")
    st.info(f"**Visionæ¨¡å‹**: {VISION_MODEL}")
    if DUAL_MODEL_ENABLED:
        st.success(f"**DeepSeek R1**: {DEEPSEEK_MODEL} âœ…")
        st.info("ğŸŒ R1 æ”¯æŒè”ç½‘æœç´¢")
    else:
        st.warning("**DeepSeek**: æœªé…ç½®")
    
    st.markdown("---")
    st.header("ğŸ“Š åŠŸèƒ½è¯´æ˜")
    st.markdown("""
    ### ğŸ“ è¾“å…¥æ–¹å¼
    1. **æ–‡å­—è¾“å…¥** - ç›´æ¥è¾“å…¥é¢˜ç›®
    2. **å›¾ç‰‡ä¸Šä¼ ** - ä¸Šä¼ æˆªå›¾/ç…§ç‰‡
       - AIè‡ªåŠ¨è¯†åˆ«
       - æ”¯æŒæ‰‹å†™å’Œå°åˆ·
       - è¯†åˆ«åå¯ç¼–è¾‘
    
    ### 1ï¸âƒ£ è´¨é‡å®¡æ ¸
    - æ¸…æ™°åº¦ (0-2åˆ†)
    - æ•°å­¦ä¸¥è°¨æ€§ (0-2åˆ†)
    - å®Œæ•´æ€§ (0-2åˆ†)
    - å¯è§£æ€§ (0-2åˆ†)
    - æ•™è‚²ä»·å€¼ (0-2åˆ†)
    
    ### 2ï¸âƒ£ åŸåˆ›åº¦æ£€æµ‹
    - ğŸ¤– åŒæ¨¡å‹äº¤å‰éªŒè¯
    - ğŸ“Š ç»“æœå¯¹æ¯”åˆ†æ
    - ğŸ” æ¥æºé“¾æ¥è¿½æº¯
    """)

# ä¸»å†…å®¹
col1, col2 = st.columns([1, 1])

with col1:
    st.header("ğŸ“ è¾“å…¥æ•°å­¦é¢˜ç›®")
    
    # é€‰æ‹©è¾“å…¥æ–¹å¼
    input_method = st.radio(
        "é€‰æ‹©è¾“å…¥æ–¹å¼ï¼š",
        ["ğŸ’¬ æ–‡å­—è¾“å…¥", "ğŸ“· å›¾ç‰‡ä¸Šä¼ "],
        horizontal=True
    )
    
    problem_text = ""
    
    if input_method == "ğŸ’¬ æ–‡å­—è¾“å…¥":
        # æ–‡å­—è¾“å…¥
        problem_text = st.text_area(
            "é¢˜ç›®å†…å®¹",
            height=300,
            placeholder="è¯·è¾“å…¥è¦å®¡æ ¸çš„æ•°å­¦é¢˜ç›®...\n\nä¾‹å¦‚ï¼š\nåœ¨ç›´è§’ä¸‰è§’å½¢ä¸­ï¼Œä¸¤æ¡ç›´è§’è¾¹é•¿åº¦åˆ†åˆ«ä¸º3å’Œ4ï¼Œæ±‚æ–œè¾¹é•¿åº¦ã€‚",
            key="text_input"
        )
    
    else:
        # å›¾ç‰‡ä¸Šä¼ 
        st.markdown("#### ğŸ“· ä¸Šä¼ é¢˜ç›®å›¾ç‰‡")
        st.info("ğŸ’¡ æ”¯æŒï¼šæˆªå›¾ã€æ‹ç…§ã€æ‰«æä»¶")
        
        uploaded_file = st.file_uploader(
            "é€‰æ‹©å›¾ç‰‡æ–‡ä»¶",
            type=["png", "jpg", "jpeg", "webp"],
            help="æ”¯æŒ PNGã€JPGã€JPEGã€WEBP æ ¼å¼"
        )
        
        if uploaded_file is not None:
            # æ˜¾ç¤ºä¸Šä¼ çš„å›¾ç‰‡
            image = Image.open(uploaded_file)
            st.image(image, caption="ä¸Šä¼ çš„å›¾ç‰‡", use_container_width=True)
            
            # OCR è¯†åˆ«æŒ‰é’®
            if st.button("ğŸ¤– AIè¯†åˆ«é¢˜ç›®", type="primary", use_container_width=True):
                with st.spinner("ğŸ” GPT-4o æ­£åœ¨è¯†åˆ«å›¾ç‰‡ä¸­çš„é¢˜ç›®..."):
                    extracted_text = extract_text_from_image(uploaded_file)
                    st.session_state['extracted_text'] = extracted_text
            
            # æ˜¾ç¤ºè¯†åˆ«ç»“æœï¼ˆå¯ç¼–è¾‘ï¼‰
            if 'extracted_text' in st.session_state:
                st.markdown("#### âœ… è¯†åˆ«ç»“æœï¼ˆå¯ç¼–è¾‘ï¼‰ï¼š")
                problem_text = st.text_area(
                    "è¯†åˆ«çš„é¢˜ç›®å†…å®¹",
                    value=st.session_state['extracted_text'],
                    height=200,
                    help="AIè¯†åˆ«çš„ç»“æœï¼Œå¦‚æœ‰é”™è¯¯å¯ä»¥ç›´æ¥ç¼–è¾‘ä¿®æ”¹",
                    key="extracted_text_area"
                )
                
                if "âŒ" in problem_text:
                    st.error("å›¾ç‰‡è¯†åˆ«å¤±è´¥ï¼Œè¯·é‡æ–°ä¸Šä¼ æˆ–ä½¿ç”¨æ–‡å­—è¾“å…¥")
                    problem_text = ""
    
    # å®¡æ ¸æŒ‰é’®
    st.markdown("---")
    button_col1, button_col2 = st.columns(2)
    
    with button_col1:
        review_button = st.button("ğŸ“Š è´¨é‡å®¡æ ¸", type="primary", use_container_width=True)
    
    with button_col2:
        originality_button = st.button("ğŸ” åŸåˆ›åº¦æ£€æµ‹ï¼ˆåŒæ¨¡å‹ï¼‰", type="secondary", use_container_width=True)

with col2:
    st.header("ğŸ“Š åˆ†æç»“æœ")
    
    # è´¨é‡å®¡æ ¸
    if review_button:
        if not problem_text or not problem_text.strip():
            st.error("âš ï¸ è¯·è¾“å…¥é¢˜ç›®å†…å®¹æˆ–ä¸Šä¼ å›¾ç‰‡ï¼")
        else:
            with st.spinner("ğŸ¤” GPT-5.1 æ­£åœ¨åˆ†æé¢˜ç›®è´¨é‡..."):
                prompt = REVIEW_PROMPT_TEMPLATE.format(problem_text=problem_text)
                result = call_openai_api(prompt, OPENAI_API_KEY, OPENAI_MODEL)
                
                try:
                    if isinstance(result, str):
                        review_data = json.loads(result)
                    else:
                        review_data = result
                    
                    if "error" in review_data:
                        st.error(f"âŒ API è°ƒç”¨å¤±è´¥: {review_data['error']}")
                    else:
                        total_score = review_data.get('total_score', 0)
                        recommendation = review_data.get('recommendation', 'UNKNOWN')
                        
                        st.markdown(f"### {get_recommendation_emoji(recommendation)} è´¨é‡å®¡æ ¸ç»“æœ")
                        
                        score_col1, score_col2 = st.columns([1, 2])
                        with score_col1:
                            st.metric("æ€»åˆ†", f"{total_score}/10")
                        with score_col2:
                            st.markdown(f"**æ¨è**: {recommendation}")
                        
                        st.markdown("---")
                        st.markdown("#### ğŸ“ˆ è¯¦ç»†è¯„åˆ†")
                        
                        score_items = [
                            ("æ¸…æ™°åº¦", review_data.get('clarity_score', 0)),
                            ("æ•°å­¦ä¸¥è°¨æ€§", review_data.get('rigor_score', 0)),
                            ("å®Œæ•´æ€§", review_data.get('completeness_score', 0)),
                            ("å¯è§£æ€§", review_data.get('solvability_score', 0)),
                            ("æ•™è‚²ä»·å€¼", review_data.get('educational_value_score', 0))
                        ]
                        
                        for label, score in score_items:
                            progress = score / 2.0
                            st.progress(progress, text=f"{label}: {score}/2")
                        
                        st.markdown("---")
                        st.markdown("#### ğŸ’¡ è¯„å®¡ç†ç”±")
                        st.write(review_data.get('reasoning', 'æ— '))
                        
                        issues = review_data.get('issues', [])
                        if issues:
                            st.markdown("#### âš ï¸ å‘ç°çš„é—®é¢˜")
                            for issue in issues:
                                st.warning(f"â€¢ {issue}")
                        else:
                            st.success("âœ¨ æœªå‘ç°æ˜æ˜¾é—®é¢˜ï¼")
                
                except json.JSONDecodeError:
                    st.error("âŒ æ— æ³•è§£æ API è¿”å›ç»“æœ")
    
    # åŸåˆ›åº¦æ£€æµ‹ï¼ˆåŒæ¨¡å‹ï¼‰
    elif originality_button:
        if not problem_text or not problem_text.strip():
            st.error("âš ï¸ è¯·è¾“å…¥é¢˜ç›®å†…å®¹æˆ–ä¸Šä¼ å›¾ç‰‡ï¼")
        else:
            st.markdown("### ğŸ¤– åŒæ¨¡å‹åŸåˆ›åº¦æ£€æµ‹")
            
            prompt = ORIGINALITY_PROMPT_TEMPLATE.format(problem_text=problem_text)
            
            # GPT-5.1 æ£€æµ‹
            with st.spinner("ğŸ” GPT-5.1 æ­£åœ¨æ£€æµ‹..."):
                gpt_result = call_openai_api(prompt, OPENAI_API_KEY, OPENAI_MODEL)
            
            # DeepSeek R1 æ£€æµ‹
            deepseek_result = None
            if DUAL_MODEL_ENABLED:
                with st.spinner("ğŸ” DeepSeek R1 æ­£åœ¨æ£€æµ‹ï¼ˆè”ç½‘æœç´¢ä¸­ï¼‰..."):
                    deepseek_result = call_openai_api(
                        prompt, 
                        DEEPSEEK_API_KEY, 
                        DEEPSEEK_MODEL,
                        base_url="https://api.deepseek.com"
                    )
            
            # æ˜¾ç¤ºç»“æœ
            tab1, tab2, tab3 = st.tabs(["ğŸ“Š å¯¹æ¯”æ€»ç»“", "ğŸ¤– GPT-5.1", "ğŸŒ DeepSeek R1"])
            
            with tab1:
                st.markdown("#### ğŸ¯ åŒæ¨¡å‹å¯¹æ¯”")
                
                try:
                    gpt_data = json.loads(gpt_result) if isinstance(gpt_result, str) else gpt_result
                    
                    if deepseek_result:
                        ds_data = json.loads(deepseek_result) if isinstance(deepseek_result, str) else deepseek_result
                        
                        gpt_conclusion = gpt_data.get('originality_conclusion', 'UNKNOWN')
                        ds_conclusion = ds_data.get('originality_conclusion', 'UNKNOWN')
                        
                        st.markdown("##### ğŸ” æ£€æµ‹ç»“è®ºå¯¹æ¯”")
                        comp_col1, comp_col2, comp_col3 = st.columns(3)
                        
                        with comp_col1:
                            st.metric("GPT-5.1", gpt_conclusion, 
                                     delta=get_originality_emoji(gpt_conclusion))
                        
                        with comp_col2:
                            st.metric("DeepSeek R1 ğŸŒ", ds_conclusion,
                                     delta=get_originality_emoji(ds_conclusion))
                        
                        with comp_col3:
                            if gpt_conclusion == ds_conclusion:
                                st.success("âœ… ç»“è®ºä¸€è‡´\né«˜å¯ä¿¡åº¦")
                            else:
                                st.warning("âš ï¸ ç»“è®ºä¸åŒ\néœ€äººå·¥åˆ¤æ–­")
                        
                        st.markdown("---")
                        st.info("ğŸ’¡ **å»ºè®®**: æŸ¥çœ‹å„æ¨¡å‹çš„è¯¦ç»†åˆ†æï¼ˆåˆ‡æ¢åˆ°å¯¹åº”æ ‡ç­¾é¡µï¼‰")
                    
                    else:
                        st.markdown("##### ğŸ” æ£€æµ‹ç»“è®º")
                        conclusion = gpt_data.get('originality_conclusion', 'UNKNOWN')
                        st.metric("GPT-5.1", conclusion, 
                                 delta=get_originality_emoji(conclusion))
                        st.info("ğŸ’¡ é…ç½® DeepSeek API Key åå¯å¯ç”¨åŒæ¨¡å‹å¯¹æ¯”")
                
                except Exception as e:
                    st.error(f"âŒ è§£æç»“æœå¤±è´¥: {e}")
            
            # GPT-5.1 è¯¦ç»†ç»“æœ
            with tab2:
                try:
                    gpt_data = json.loads(gpt_result) if isinstance(gpt_result, str) else gpt_result
                    
                    if "error" in gpt_data:
                        st.error(f"âŒ GPT-5.1 è°ƒç”¨å¤±è´¥: {gpt_data['error']}")
                    else:
                        conclusion = gpt_data.get('originality_conclusion', 'UNKNOWN')
                        st.markdown(f"### {get_originality_emoji(conclusion)} {conclusion}")
                        
                        similar_problems = gpt_data.get('similar_problems', [])
                        if similar_problems:
                            st.markdown("#### ğŸ” å‘ç°çš„ç›¸ä¼¼é¢˜ç›®")
                            for idx, prob in enumerate(similar_problems[:3], 1):
                                with st.expander(f"ç›¸ä¼¼é¢˜ç›® {idx} - ç›¸ä¼¼åº¦: {prob.get('similarity_percentage', 0)}%"):
                                    st.markdown(f"**æ¥æº**: {prob.get('source', 'æœªçŸ¥')}")
                                    source_url = prob.get('source_url', '')
                                    if source_url and source_url.strip():
                                        if source_url.startswith('http'):
                                            st.markdown(f"**é“¾æ¥**: [{source_url}]({source_url})")
                                        else:
                                            st.markdown(f"**è¯¦ç»†å‡ºå¤„**: {source_url}")
                                    st.markdown(f"**é¢˜ç›®å†…å®¹**: {prob.get('content', 'æ— ')}")
                                    st.markdown(f"**ç›¸ä¼¼åŸå› **: {prob.get('similarity_reason', 'æ— ')}")
                        else:
                            st.success("âœ… æœªå‘ç°é«˜åº¦ç›¸ä¼¼çš„é¢˜ç›®")
                        
                        unique_aspects = gpt_data.get('unique_aspects', [])
                        if unique_aspects:
                            st.markdown("#### âœ¨ é¢˜ç›®çš„ç‹¬ç‰¹ä¹‹å¤„")
                            for aspect in unique_aspects:
                                st.success(f"â€¢ {aspect}")
                        
                        if gpt_data.get('overall_assessment'):
                            st.markdown("---")
                            st.info(f"ğŸ“ **æ•´ä½“è¯„ä¼°**: {gpt_data['overall_assessment']}")
                
                except Exception as e:
                    st.error(f"âŒ è§£æ GPT-5.1 ç»“æœå¤±è´¥: {e}")
            
            # DeepSeek è¯¦ç»†ç»“æœ
            with tab3:
                if not DUAL_MODEL_ENABLED:
                    st.warning("âš ï¸ DeepSeek æœªé…ç½®")
                elif not deepseek_result:
                    st.error("âŒ DeepSeek è°ƒç”¨å¤±è´¥")
                else:
                    try:
                        ds_data = json.loads(deepseek_result) if isinstance(deepseek_result, str) else deepseek_result
                        
                        if "error" in ds_data:
                            st.error(f"âŒ DeepSeek è°ƒç”¨å¤±è´¥: {ds_data['error']}")
                        else:
                            conclusion = ds_data.get('originality_conclusion', 'UNKNOWN')
                            st.markdown(f"### {get_originality_emoji(conclusion)} {conclusion}")
                            
                            similar_problems = ds_data.get('similar_problems', [])
                            if similar_problems:
                                st.markdown("#### ğŸ” å‘ç°çš„ç›¸ä¼¼é¢˜ç›®")
                                for idx, prob in enumerate(similar_problems[:3], 1):
                                    with st.expander(f"ç›¸ä¼¼é¢˜ç›® {idx} - ç›¸ä¼¼åº¦: {prob.get('similarity_percentage', 0)}%"):
                                        st.markdown(f"**æ¥æº**: {prob.get('source', 'æœªçŸ¥')}")
                                        source_url = prob.get('source_url', '')
                                        if source_url and source_url.strip():
                                            if source_url.startswith('http'):
                                                st.markdown(f"**é“¾æ¥**: [{source_url}]({source_url})")
                                            else:
                                                st.markdown(f"**è¯¦ç»†å‡ºå¤„**: {source_url}")
                                        st.markdown(f"**é¢˜ç›®å†…å®¹**: {prob.get('content', 'æ— ')}")
                                        st.markdown(f"**ç›¸ä¼¼åŸå› **: {prob.get('similarity_reason', 'æ— ')}")
                            else:
                                st.success("âœ… æœªå‘ç°é«˜åº¦ç›¸ä¼¼çš„é¢˜ç›®")
                    
                    except Exception as e:
                        st.error(f"âŒ è§£æ DeepSeek ç»“æœå¤±è´¥: {e}")
    
    else:
        st.info("""
        ğŸ‘ˆ è¯·åœ¨å·¦ä¾§é€‰æ‹©è¾“å…¥æ–¹å¼ï¼š
        
        **ğŸ’¬ æ–‡å­—è¾“å…¥** - ç›´æ¥è¾“å…¥é¢˜ç›®æ–‡å­—
        
        **ğŸ“· å›¾ç‰‡ä¸Šä¼ ** - ä¸Šä¼ æˆªå›¾æˆ–ç…§ç‰‡
        - ä¸Šä¼ å›¾ç‰‡åç‚¹å‡»"AIè¯†åˆ«"
        - è¯†åˆ«ç»“æœå¯ä»¥ç¼–è¾‘ä¿®æ”¹
        - ç„¶åé€‰æ‹©å®¡æ ¸åŠŸèƒ½
        """)

# åº•éƒ¨è¯´æ˜
st.markdown("---")
st.markdown("""
<div style='text-align: center; color: gray;'>
    <p><strong>æ•°å­¦é¢˜ç›®å®¡æ ¸ç³»ç»Ÿ</strong> - å›¾ç‰‡è¯†åˆ«ç‰ˆ</p>
    <p>æ”¯æŒæ–‡å­—è¾“å…¥ + å›¾ç‰‡ä¸Šä¼  | GPT-5.1 + DeepSeek R1 | AI OCRè¯†åˆ«</p>
</div>
""", unsafe_allow_html=True)

