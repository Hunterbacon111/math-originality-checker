#!/usr/bin/env python3
"""
æ•°å­¦é¢˜ç›®è´¨é‡å®¡æ ¸ä¸åŸåˆ›åº¦æ£€æµ‹ç³»ç»Ÿ - å›¾ç‰‡è¯†åˆ«ç‰ˆ
æ”¯æŒæ–‡å­—è¾“å…¥å’Œå›¾ç‰‡ä¸Šä¼ ï¼ˆOCRè¯†åˆ«ï¼‰
"""
import streamlit as st
import json
import time
import os
import base64
from openai import OpenAI
from PIL import Image
import io

# æ³¨æ„ï¼šç¯å¢ƒå˜é‡å·²åœ¨ä¸» app.py ä¸­åŠ è½½

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="è´¨é‡å®¡æ ¸ä¸åŸåˆ›åº¦æ£€æµ‹",
    page_icon="ğŸ“‹",
    layout="wide"
)

# API é…ç½®
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
DEEPSEEK_API_KEY = os.getenv("DEEPSEEK_API_KEY")
MISTRAL_API_KEY = os.getenv("MISTRAL_API_KEY")
OPENAI_MODEL = os.getenv("OPENAI_MODEL", "gpt-5.1-chat-latest")
MISTRAL_VISION_MODEL = "pixtral-large-latest"  # Mistral çš„è§†è§‰æ¨¡å‹
DEEPSEEK_MODEL = os.getenv("DEEPSEEK_MODEL", "deepseek-chat")

# æ£€æŸ¥é…ç½®
if not OPENAI_API_KEY:
    st.error("âŒ æœªé…ç½® OPENAI_API_KEY")
    st.stop()

if not MISTRAL_API_KEY:
    st.error("âŒ æœªé…ç½® MISTRAL_API_KEYï¼ˆå›¾åƒè¯†åˆ«éœ€è¦ï¼‰")
    st.stop()

# DeepSeek R1 æš‚æ—¶ç¦ç”¨ï¼ˆå‡†ç¡®æ€§é—®é¢˜ï¼‰
DUAL_MODEL_ENABLED = False

# è´¨é‡å®¡æ ¸ Prompt
REVIEW_PROMPT_TEMPLATE = """You are an expert mathematics educator reviewing problem quality.

**IMPORTANT**: Do NOT attempt to solve the problem or verify if the answer is correct. Focus ONLY on evaluating the problem statement itself.

Evaluate this mathematical problem based on these 5 criteria:
1. **Clarity** (0-2 points): Is the problem statement clear, unambiguous, and easy to understand?
2. **Mathematical Rigor** (0-2 points): Are mathematical notations, symbols, and expressions used correctly and rigorously?
3. **Completeness** (0-2 points): Does the problem provide all necessary information? Are conditions sufficient to solve it?
4. **Solvability** (0-2 points): Does the problem appear to have a well-defined solution (unique or a clear solution set)?
5. **Educational Value** (0-2 points): Is this a meaningful mathematical problem worth studying?

**Problem to Review:**
{problem_text}

**Your Task:**
Evaluate the problem based on the 5 criteria above and respond in JSON format:

{{
  "clarity_score": 0-2,
  "rigor_score": 0-2,
  "completeness_score": 0-2,
  "solvability_score": 0-2,
  "educational_value_score": 0-2,
  "total_score": 0-10,
  "issues": ["list specific issues, if any"],
  "reasoning": "brief explanation of your evaluation",
  "recommendation": "ACCEPT (â‰¥7) / BORDERLINE (5-6) / REJECT (<5)"
}}

**Remember**: Focus on problem quality, NOT answer correctness!
"""

# åŸåˆ›åº¦æ£€æµ‹ Prompt - GPT-5.1 ç‰ˆæœ¬
ORIGINALITY_PROMPT_GPT = """ä½ ç°åœ¨æ˜¯ä¸€åèµ„æ·±çš„å­¦æœ¯æŸ¥é‡ä¸“å®¶å’Œé«˜çº§æœç´¢å·¥ç¨‹ä¸“å®¶ã€‚

Task: è¯·é’ˆå¯¹æˆ‘æä¾›çš„é¢˜ç›®è¿›è¡Œæ·±åº¦åˆ†æï¼ŒæŸ¥éªŒè¯¥é¢˜ç›®çš„åŸåˆ›åº¦ï¼ˆæ˜¯å¦åœ¨ä½ çš„çŸ¥è¯†åº“ä¸­å­˜åœ¨åŸé¢˜æˆ–é«˜åº¦ç›¸ä¼¼çš„å˜ä½“ï¼‰ã€‚

**é‡è¦è¯´æ˜**ï¼š
- ä¸¥ç¦ç»™å‡ºä»»ä½•è§£é¢˜æ­¥éª¤æˆ–ç­”æ¡ˆ
- ä¸è¦å°è¯•è§£é¢˜
- åªåˆ†æé¢˜ç›®æœ¬èº«çš„åŸåˆ›æ€§

**æ£€ç´¢ç­–ç•¥ (Search Strategy)**:
1. å…³é”®è¯æŠ½æ ·ï¼šæå–é¢˜ç›®çš„æ ¸å¿ƒçŸ¥è¯†ç‚¹ã€ç½•è§æœ¯è¯­å’Œæ•°æ®ç»„åˆ
2. ç»“æ„åŒ–åŒ¹é…ï¼šå¿½ç•¥å…·ä½“çš„æ•°å€¼ï¼Œé‡ç‚¹å…³æ³¨é¢˜ç›®çš„é€»è¾‘ç»“æ„ã€è®¾å®šèƒŒæ™¯å’Œå·²çŸ¥æ¡ä»¶çš„ç»„åˆæ–¹å¼
3. å¤šå¹³å°è¦†ç›–ï¼šåœ¨ä½ çš„çŸ¥è¯†åº“ä¸­æ£€ç´¢åŒ…æ‹¬ä½†ä¸é™äºï¼š
   - ç»å…¸æ•™æï¼ˆå¦‚åŒæµé«˜ç­‰æ•°å­¦ã€æ™®æ—æ–¯é¡¿å¾®ç§¯åˆ†ç­‰ï¼‰
   - æ ‡å‡†é¢˜åº“ï¼ˆé«˜è€ƒçœŸé¢˜ã€è€ƒç ”çœŸé¢˜ã€AMCã€IMO ç­‰ï¼‰
   - çŸ¥åæ•™è‚²å¹³å°å’Œè®ºå›ï¼ˆAOPSã€çŸ¥ä¹ã€ç™¾åº¦æ•™è‚²ã€StackExchangeã€Chegg ç­‰ï¼‰
   - å­¦æœ¯è®ºæ–‡å’Œç«èµ›é¢˜åº“

**åˆ†æè¦æ±‚ (Analysis Requirements)**:
- ä¸ä»…è¦çœ‹è¯­ä¹‰å’Œæ•°å­—ï¼Œè¿˜è¦å…³æ³¨è§£é¢˜è·¯å¾„çš„ç›¸ä¼¼æ€§
- **å¦‚æœå‘ç°ç›¸ä¼¼é¢˜ç›®ï¼Œå¿…é¡»æä¾›å…·ä½“æ¥æºä¿¡æ¯**ï¼š
  - å¦‚æœæ¥è‡ªç½‘ç«™/è®ºå›ï¼Œæä¾›å®Œæ•´çš„URLé“¾æ¥
  - å¦‚æœæ¥è‡ªä¹¦ç±/è¯•å·ï¼Œæä¾›è¯¦ç»†å‡ºå¤„
  - å¦‚æœæ¥è‡ªç«èµ›ï¼Œæä¾›å¹´ä»½å’Œé¢˜å·
- åˆ†æé¢˜ç›®çš„ç‹¬ç‰¹ä¹‹å¤„

**é¢˜ç›®å†…å®¹**:
{problem_text}

**è¾“å‡ºæ ¼å¼ (Output Format)**:
è¯·ä»¥ JSON æ ¼å¼è¾“å‡ºï¼ŒåŒ…å«ä»¥ä¸‹å­—æ®µï¼š

{{
  "originality_conclusion": "åŸåˆ› / ç–‘ä¼¼æ¬è¿ / ç»“æ„é›·åŒ",
  "similar_problems": [
    {{
      "source": "æ¥æºåç§°",
      "source_url": "å…·ä½“é“¾æ¥æˆ–è¯¦ç»†å‡ºå¤„",
      "content": "ç›¸ä¼¼é¢˜ç›®çš„ç®€è¦æè¿°",
      "similarity_percentage": 85,
      "similarity_reason": "ç›¸ä¼¼ä¹‹å¤„çš„å…·ä½“è¯´æ˜"
    }}
  ],
  "unique_aspects": ["åˆ—å‡ºé¢˜ç›®çš„ç‹¬ç‰¹ä¹‹å¤„"],
  "keyword_analysis": "å…³é”®è¯å’Œæ ¸å¿ƒæ¦‚å¿µåˆ†æ",
  "structure_analysis": "é¢˜ç›®ç»“æ„å’Œé€»è¾‘æ¡†æ¶åˆ†æ",
  "overall_assessment": "æ•´ä½“è¯„ä¼°è¯´æ˜"
}}

**é‡è¦æé†’**: 
1. å¿…é¡»æä¾›å…·ä½“çš„æ¥æºé“¾æ¥æˆ–è¯¦ç»†å‡ºå¤„
2. ä¸è¦ç»™åŸåˆ›åº¦æ‰“åˆ†
3. ä¸¥ç¦åœ¨ä»»ä½•å­—æ®µä¸­åŒ…å«è§£é¢˜æ­¥éª¤æˆ–ç­”æ¡ˆï¼
"""

# åŸåˆ›åº¦æ£€æµ‹ Prompt - DeepSeek R1 ç‰ˆæœ¬ï¼ˆå¹³è¡¡å‡†ç¡®æ€§ä¸æŸ¥é‡èƒ½åŠ›ï¼‰
ORIGINALITY_PROMPT_DEEPSEEK = """ä½ æ˜¯ä¸€åä¸¥è°¨çš„å­¦æœ¯æŸ¥é‡ä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯åˆ†æé¢˜ç›®çš„åŸåˆ›åº¦ã€‚

âš ï¸ **é‡è¦åŸåˆ™**ï¼š
1. **å‡†ç¡®æ€§ç¬¬ä¸€**ï¼šä¸è¦ç¼–é€ ä¸å­˜åœ¨çš„å…·ä½“é“¾æ¥ï¼ˆå¦‚å®Œæ•´URLï¼‰
2. **å¯ä»¥å‘ç°ç›¸ä¼¼æ€§**ï¼šå¦‚æœé¢˜ç›®ç»“æ„ã€é€»è¾‘ã€è€ƒç‚¹ä¸ä½ çŸ¥è¯†åº“ä¸­çš„å†…å®¹ç›¸ä¼¼ï¼Œåº”è¯¥æŒ‡å‡º
3. **æ¥æºåˆ†çº§å¤„ç†**ï¼š
   - âœ… **ç¡®å®šæ¥æº**ï¼šå¦‚æœä½ æ˜ç¡®çŸ¥é“æ¥è‡ªæŸæœ¬æ•™æã€æŸä¸ªç«èµ›ã€æŸä¸ªçŸ¥åé¢˜åº“ï¼Œå¯ä»¥è¯´æ˜ï¼ˆä½†ä¸è¦ç¼–é€ å…·ä½“é¡µç æˆ–é¢˜å·ï¼‰
   - âš ï¸ **ç»“æ„ç›¸ä¼¼**ï¼šå¦‚æœåªæ˜¯å‘ç°é¢˜ç›®ç±»å‹ã€è§£é¢˜æ€è·¯ç›¸ä¼¼ï¼Œä½†è®°ä¸æ¸…å…·ä½“å‡ºå¤„ï¼Œå¯ä»¥è¯´"ç»“æ„é›·åŒ"å¹¶åˆ†æç›¸ä¼¼ç‚¹
   - âŒ **åŸåˆ›**ï¼šå¦‚æœç¡®å®æ²¡æœ‰å°è±¡ï¼Œæ‰åˆ¤å®šä¸ºåŸåˆ›

**é‡è¦ï¼šè¯·ä¸¥æ ¼æŒ‰ç…§ JSON æ ¼å¼è¾“å‡ºç»“æœï¼ˆJSON format requiredï¼‰ã€‚**

**é¢˜ç›®å†…å®¹**:
{problem_text}

**æ£€ç´¢ç­–ç•¥**:
1. åˆ†æé¢˜ç›®çš„æ ¸å¿ƒè€ƒç‚¹ã€é€»è¾‘ç»“æ„ã€è®¾å®šèƒŒæ™¯
2. åœ¨ä½ çš„çŸ¥è¯†åº“ä¸­æœç´¢ç±»ä¼¼çš„é¢˜ç›®æˆ–é¢˜å‹
3. å¦‚æœå‘ç°ç›¸ä¼¼å†…å®¹ï¼š
   - è¯´æ˜ç›¸ä¼¼ä¹‹å¤„ï¼ˆè€ƒç‚¹ã€ç»“æ„ã€è®¾å®šç­‰ï¼‰
   - å¦‚æœè®°å¾—å¤§è‡´æ¥æºï¼ˆå¦‚"é«˜è€ƒçœŸé¢˜""AMCç«èµ›""å¾®ç§¯åˆ†æ•™æ"ï¼‰ï¼Œå¯ä»¥è¯´æ˜
   - å¦‚æœä¸è®°å¾—å…·ä½“å‡ºå¤„ï¼Œå°±è¯´"æ¥æºï¼šè®°å¿†ä¸­è§è¿‡ç±»ä¼¼é¢˜å‹ï¼Œä½†æ— æ³•æä¾›å‡†ç¡®å‡ºå¤„"
4. **ç»å¯¹ä¸è¦ç¼–é€ å®Œæ•´çš„URLã€å…·ä½“çš„é¢˜å·ã€é¡µç **

**è¾“å‡ºæ ¼å¼ï¼ˆJSON formatï¼‰**:
è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹ JSON ç»“æ„è¾“å‡ºï¼š

{{
  "originality_conclusion": "åŸåˆ› / ç–‘ä¼¼æ¬è¿ / ç»“æ„é›·åŒ",
  "similar_problems": [
    {{
      "source": "æ¥æºç±»å‹ï¼ˆå¦‚'é«˜è€ƒçœŸé¢˜''ç«èµ›é¢˜åº“''å¾®ç§¯åˆ†æ•™æ'ç­‰ï¼Œå¦‚æœåªæ˜¯é¢˜å‹ç›¸ä¼¼å°±å†™'å¸¸è§é¢˜å‹'ï¼‰",
      "source_url": "ã€å¦‚æœä½ ç¡®åˆ‡çŸ¥é“æ¥æºã€‘å†™è¯¦ç»†å‡ºå¤„ï¼ˆå¦‚'2018å¹´å…¨å›½å·I''AMC 12 2020'ï¼‰ï¼›ã€å¦‚æœä¸ç¡®å®šå…·ä½“å‡ºå¤„ã€‘å†™'è®°å¿†ä¸­è§è¿‡ç±»ä¼¼ï¼Œä½†æ— å‡†ç¡®å‡ºå¤„'ï¼›ã€ç»å¯¹ä¸è¦ã€‘ç¼–é€ å…·ä½“ç½‘å€é“¾æ¥",
      "content": "ç›¸ä¼¼é¢˜ç›®çš„æ ¸å¿ƒç‰¹å¾æè¿°ï¼ˆä¸è¦ç»™å‡ºå®Œæ•´é¢˜ç›®ï¼‰",
      "similarity_percentage": 70,
      "similarity_reason": "è¯¦ç»†è¯´æ˜ç›¸ä¼¼ä¹‹å¤„ï¼ˆè€ƒç‚¹ã€ç»“æ„ã€é€»è¾‘ã€è®¾å®šç­‰ï¼‰",
      "confidence_level": "é«˜ï¼ˆç¡®å®šè§è¿‡ï¼‰/ä¸­ï¼ˆå°è±¡ä¸­æœ‰ç±»ä¼¼ï¼‰/ä½ï¼ˆä»…é¢˜å‹ç›¸ä¼¼ï¼‰"
    }}
  ],
  "unique_aspects": ["åˆ—å‡ºé¢˜ç›®çš„ç‹¬ç‰¹ä¹‹å¤„æˆ–åˆ›æ–°ç‚¹"],
  "keyword_analysis": "æ ¸å¿ƒè€ƒç‚¹å’Œå…³é”®æ¦‚å¿µ",
  "structure_analysis": "é¢˜ç›®çš„é€»è¾‘ç»“æ„å’Œè§£é¢˜æ€è·¯",
  "overall_assessment": "ç»¼åˆè¯„ä¼°ï¼ˆæ—¢è¦æŒ‡å‡ºç›¸ä¼¼æ€§ï¼Œä¹Ÿè¦æŒ‡å‡ºç‹¬ç‰¹æ€§ï¼‰",
  "search_note": "ä½ çš„æ£€ç´¢æ€è·¯å’Œåˆ¤æ–­ä¾æ®"
}}

**è¾“å‡ºè¦æ±‚**ï¼š
- âœ… **å¯ä»¥**æŒ‡å‡ºé¢˜å‹ã€è€ƒç‚¹ã€ç»“æ„çš„ç›¸ä¼¼æ€§
- âœ… **å¯ä»¥**è¯´"é«˜è€ƒå¸¸è§é¢˜å‹""ç«èµ›ç»å…¸é¢˜å‹"ç­‰ç¬¼ç»Ÿæ¥æº
- âœ… **å¯ä»¥**è¯´"è®°å¿†ä¸­è§è¿‡ç±»ä¼¼ï¼Œä½†æ— å‡†ç¡®å‡ºå¤„"
- âŒ **ä¸è¦**ç¼–é€ å®Œæ•´çš„URLé“¾æ¥ï¼ˆå¦‚ https://...ï¼‰
- âŒ **ä¸è¦**ç¼–é€ å…·ä½“çš„é¢˜å·ã€é¡µç ï¼ˆé™¤éä½ 100%ç¡®å®šï¼‰
- âŒ **ä¸è¦**å› ä¸ºè¿‡äºè°¨æ…è€ŒæŠŠæ‰€æœ‰é¢˜ç›®éƒ½åˆ¤ä¸º"åŸåˆ›"

**ä¸¥ç¦ç»™å‡ºè§£é¢˜æ­¥éª¤æˆ–ç­”æ¡ˆï¼**
"""

def encode_image_to_base64(image_file):
    """å°†ä¸Šä¼ çš„å›¾ç‰‡è½¬æ¢ä¸º base64"""
    image = Image.open(image_file)
    buffered = io.BytesIO()
    image.save(buffered, format="PNG")
    return base64.b64encode(buffered.getvalue()).decode('utf-8')

def extract_text_from_image(image_file):
    """ä½¿ç”¨ Mistral Pixtral ä»å›¾ç‰‡ä¸­æå–æ•°å­¦é¢˜ç›®"""
    try:
        # ä½¿ç”¨ Mistral APIï¼ˆå…¼å®¹ OpenAI SDKï¼‰
        client = OpenAI(
            api_key=MISTRAL_API_KEY,
            base_url="https://api.mistral.ai/v1"
        )
        
        # å°†å›¾ç‰‡è½¬æ¢ä¸º base64
        base64_image = encode_image_to_base64(image_file)
        
        response = client.chat.completions.create(
            model=MISTRAL_VISION_MODEL,
            messages=[
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "text",
                            "text": """You are an expert OCR system for mathematical content. Please carefully extract ALL text from this image.

CRITICAL REQUIREMENTS:
1. Extract ALL visible text, formulas, and mathematical symbols
2. Preserve the exact structure and formatting
3. Use proper mathematical notation (e.g., âˆ ABC, Â°, âˆš, âˆ«, etc.)
4. If there are diagrams, describe them briefly
5. Include ALL text - do NOT refuse or skip any content
6. Output ONLY the extracted text, no explanations

Extract the complete mathematical problem from the image:"""
                        },
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/png;base64,{base64_image}"
                            }
                        }
                    ]
                }
            ],
            max_tokens=2000,
            temperature=0.1
        )
        
        extracted = response.choices[0].message.content.strip()
        
        # æ£€æŸ¥è¿”å›å†…å®¹
        if not extracted or len(extracted) < 10:
            return "âŒ è¯†åˆ«å¤±è´¥ï¼šè¿”å›å†…å®¹è¿‡çŸ­ï¼Œè¯·é‡æ–°ä¸Šä¼ å›¾ç‰‡æˆ–ä½¿ç”¨æ–‡å­—è¾“å…¥"
        
        # æ£€æŸ¥æ˜¯å¦æ‹’ç»è¯†åˆ«
        refusal_keywords = ["sorry", "can't", "cannot", "unable", "refuse"]
        if any(keyword in extracted.lower() for keyword in refusal_keywords):
            return f"âŒ Mistral æ‹’ç»è¯†åˆ«æ­¤å›¾ç‰‡\n\nè¿”å›å†…å®¹: {extracted}\n\nğŸ’¡ è¯·ä½¿ç”¨æ–‡å­—è¾“å…¥åŠŸèƒ½"
        
        return extracted
    
    except Exception as e:
        return f"""âŒ å›¾ç‰‡è¯†åˆ«å¤±è´¥: {str(e)}

ğŸ’¡ å¯èƒ½çš„åŸå› ï¼š
1. Mistral API Key é…ç½®é”™è¯¯
2. ç½‘ç»œè¿æ¥é—®é¢˜
3. å›¾ç‰‡æ ¼å¼ä¸æ”¯æŒ

ğŸ”§ è§£å†³æ–¹æ¡ˆï¼š
1. ä½¿ç”¨ **æ–‡å­—è¾“å…¥** åŠŸèƒ½æ‰‹åŠ¨è¾“å…¥é¢˜ç›®
2. æ£€æŸ¥ Mistral API Key æ˜¯å¦æ­£ç¡®
3. å°è¯•é‡æ–°ä¸Šä¼ æ›´æ¸…æ™°çš„å›¾ç‰‡"""

def call_openai_api(prompt, api_key, model, base_url="https://api.openai.com/v1", use_json_format=True):
    """è°ƒç”¨ APIï¼ˆæ”¯æŒ OpenAI å’Œ DeepSeekï¼‰"""
    try:
        client = OpenAI(api_key=api_key, base_url=base_url)
        
        # æ„å»ºè¯·æ±‚å‚æ•°
        request_params = {
            "model": model,
            "messages": [{"role": "user", "content": prompt}]
        }
        
        # åªæœ‰åœ¨æ˜ç¡®è¦æ±‚ JSON æ ¼å¼æ—¶æ‰æ·»åŠ  response_format
        if use_json_format:
            request_params["response_format"] = {"type": "json_object"}
        
        response = client.chat.completions.create(**request_params)
        return response.choices[0].message.content
    except Exception as e:
        return {"error": str(e)}

def get_recommendation_emoji(recommendation):
    """æ ¹æ®æ¨èç»“æœè¿”å›è¡¨æƒ…ç¬¦å·"""
    if "ACCEPT" in recommendation:
        return "âœ…"
    elif "BORDERLINE" in recommendation:
        return "âš ï¸"
    else:
        return "âŒ"

def get_originality_emoji(conclusion):
    """æ ¹æ®åŸåˆ›åº¦ç»“è®ºè¿”å›è¡¨æƒ…ç¬¦å·"""
    if "åŸåˆ›" in conclusion:
        return "âœ…"
    elif "ç»“æ„é›·åŒ" in conclusion:
        return "âš ï¸"
    else:
        return "âŒ"

# ä¸»ç•Œé¢
st.title("ğŸ“‹ è´¨é‡å®¡æ ¸ä¸åŸåˆ›åº¦æ£€æµ‹")
st.markdown("**æ”¯æŒæ–‡å­—è¾“å…¥ + å›¾ç‰‡ä¸Šä¼ ï¼ˆAIè¯†åˆ«ï¼‰**")
st.markdown("---")

# ä¾§è¾¹æ 
with st.sidebar:
    st.header("âš™ï¸ ç³»ç»Ÿé…ç½®")
    st.info(f"**GPTæ¨¡å‹**: {OPENAI_MODEL}")
    st.success(f"**Visionæ¨¡å‹**: Mistral Pixtral ğŸ“·")
    st.info("ğŸ’¡ **åŸåˆ›åº¦æ£€æµ‹**: ä»…ä½¿ç”¨ GPT-5.1")
    
    st.markdown("---")
    st.header("ğŸ“Š åŠŸèƒ½è¯´æ˜")
    st.markdown("""
    ### ğŸ“ è¾“å…¥æ–¹å¼
    1. **æ–‡å­—è¾“å…¥** - ç›´æ¥è¾“å…¥é¢˜ç›®
    2. **å›¾ç‰‡ä¸Šä¼ ** - ä¸Šä¼ æˆªå›¾/ç…§ç‰‡
       - AIè‡ªåŠ¨è¯†åˆ«
       - æ”¯æŒæ‰‹å†™å’Œå°åˆ·
       - è¯†åˆ«åå¯ç¼–è¾‘
    
    ### 1ï¸âƒ£ è´¨é‡å®¡æ ¸
    - æ¸…æ™°åº¦ (0-2åˆ†)
    - æ•°å­¦ä¸¥è°¨æ€§ (0-2åˆ†)
    - å®Œæ•´æ€§ (0-2åˆ†)
    - å¯è§£æ€§ (0-2åˆ†)
    - æ•™è‚²ä»·å€¼ (0-2åˆ†)
    
    ### 2ï¸âƒ£ åŸåˆ›åº¦æ£€æµ‹
    - ğŸ¤– GPT-5.1 æ·±åº¦åˆ†æ
    - ğŸ“Š ç»“æœå¯¹æ¯”åˆ†æ
    - ğŸ” æ¥æºé“¾æ¥è¿½æº¯
    """)

# ä¸»å†…å®¹
col1, col2 = st.columns([1, 1])

with col1:
    st.header("ğŸ“ è¾“å…¥æ•°å­¦é¢˜ç›®")
    
    # é€‰æ‹©è¾“å…¥æ–¹å¼
    input_method = st.radio(
        "é€‰æ‹©è¾“å…¥æ–¹å¼ï¼š",
        ["ğŸ’¬ æ–‡å­—è¾“å…¥", "ğŸ“· å›¾ç‰‡ä¸Šä¼ "],
        horizontal=True
    )
    
    problem_text = ""
    
    if input_method == "ğŸ’¬ æ–‡å­—è¾“å…¥":
        # æ–‡å­—è¾“å…¥
        problem_text = st.text_area(
            "é¢˜ç›®å†…å®¹",
            height=300,
            placeholder="è¯·è¾“å…¥è¦å®¡æ ¸çš„æ•°å­¦é¢˜ç›®...\n\nä¾‹å¦‚ï¼š\nåœ¨ç›´è§’ä¸‰è§’å½¢ä¸­ï¼Œä¸¤æ¡ç›´è§’è¾¹é•¿åº¦åˆ†åˆ«ä¸º3å’Œ4ï¼Œæ±‚æ–œè¾¹é•¿åº¦ã€‚",
            key="text_input"
        )
    
    else:
        # å›¾ç‰‡ä¸Šä¼ 
        st.markdown("#### ğŸ“· ä¸Šä¼ é¢˜ç›®å›¾ç‰‡")
        st.info("ğŸ’¡ æ”¯æŒï¼šæˆªå›¾ã€æ‹ç…§ã€æ‰«æä»¶")
        
        uploaded_file = st.file_uploader(
            "é€‰æ‹©å›¾ç‰‡æ–‡ä»¶",
            type=["png", "jpg", "jpeg", "webp"],
            help="æ”¯æŒ PNGã€JPGã€JPEGã€WEBP æ ¼å¼"
        )
        
        if uploaded_file is not None:
            # æ˜¾ç¤ºä¸Šä¼ çš„å›¾ç‰‡
            image = Image.open(uploaded_file)
            st.image(image, caption="ä¸Šä¼ çš„å›¾ç‰‡", use_container_width=True)
            
            # OCR è¯†åˆ«æŒ‰é’®
            if st.button("ğŸ¤– AIè¯†åˆ«é¢˜ç›®", type="primary", use_container_width=True):
                with st.spinner("ğŸ” Mistral Pixtral æ­£åœ¨è¯†åˆ«å›¾ç‰‡ä¸­çš„é¢˜ç›®..."):
                    extracted_text = extract_text_from_image(uploaded_file)
                    st.session_state['extracted_text'] = extracted_text
            
            # æ˜¾ç¤ºè¯†åˆ«ç»“æœï¼ˆå¯ç¼–è¾‘ï¼‰
            if 'extracted_text' in st.session_state:
                st.markdown("#### âœ… è¯†åˆ«ç»“æœï¼ˆå¯ç¼–è¾‘ï¼‰ï¼š")
                problem_text = st.text_area(
                    "è¯†åˆ«çš„é¢˜ç›®å†…å®¹",
                    value=st.session_state['extracted_text'],
                    height=200,
                    help="AIè¯†åˆ«çš„ç»“æœï¼Œå¦‚æœ‰é”™è¯¯å¯ä»¥ç›´æ¥ç¼–è¾‘ä¿®æ”¹",
                    key="extracted_text_area"
                )
                
                if "âŒ" in problem_text:
                    st.error("å›¾ç‰‡è¯†åˆ«å¤±è´¥ï¼Œè¯·é‡æ–°ä¸Šä¼ æˆ–ä½¿ç”¨æ–‡å­—è¾“å…¥")
                    problem_text = ""
    
    # å®¡æ ¸æŒ‰é’®
    st.markdown("---")
    button_col1, button_col2 = st.columns(2)
    
    with button_col1:
        review_button = st.button("ğŸ“Š è´¨é‡å®¡æ ¸", type="primary", use_container_width=True)
    
    with button_col2:
        originality_button = st.button("ğŸ” åŸåˆ›åº¦æ£€æµ‹", type="secondary", use_container_width=True)

with col2:
    st.header("ğŸ“Š åˆ†æç»“æœ")
    
    # è´¨é‡å®¡æ ¸
    if review_button:
        if not problem_text or not problem_text.strip():
            st.error("âš ï¸ è¯·è¾“å…¥é¢˜ç›®å†…å®¹æˆ–ä¸Šä¼ å›¾ç‰‡ï¼")
        else:
            with st.spinner("ğŸ¤” GPT-5.1 æ­£åœ¨åˆ†æé¢˜ç›®è´¨é‡..."):
                prompt = REVIEW_PROMPT_TEMPLATE.format(problem_text=problem_text)
                result = call_openai_api(prompt, OPENAI_API_KEY, OPENAI_MODEL)
                
                try:
                    if isinstance(result, str):
                        review_data = json.loads(result)
                    else:
                        review_data = result
                    
                    if "error" in review_data:
                        st.error(f"âŒ API è°ƒç”¨å¤±è´¥: {review_data['error']}")
                    else:
                        total_score = review_data.get('total_score', 0)
                        recommendation = review_data.get('recommendation', 'UNKNOWN')
                        
                        st.markdown(f"### {get_recommendation_emoji(recommendation)} è´¨é‡å®¡æ ¸ç»“æœ")
                        
                        score_col1, score_col2 = st.columns([1, 2])
                        with score_col1:
                            st.metric("æ€»åˆ†", f"{total_score}/10")
                        with score_col2:
                            st.markdown(f"**æ¨è**: {recommendation}")
                        
                        st.markdown("---")
                        st.markdown("#### ğŸ“ˆ è¯¦ç»†è¯„åˆ†")
                        
                        score_items = [
                            ("æ¸…æ™°åº¦", review_data.get('clarity_score', 0)),
                            ("æ•°å­¦ä¸¥è°¨æ€§", review_data.get('rigor_score', 0)),
                            ("å®Œæ•´æ€§", review_data.get('completeness_score', 0)),
                            ("å¯è§£æ€§", review_data.get('solvability_score', 0)),
                            ("æ•™è‚²ä»·å€¼", review_data.get('educational_value_score', 0))
                        ]
                        
                        for label, score in score_items:
                            progress = score / 2.0
                            st.progress(progress, text=f"{label}: {score}/2")
                        
                        st.markdown("---")
                        st.markdown("#### ğŸ’¡ è¯„å®¡ç†ç”±")
                        st.write(review_data.get('reasoning', 'æ— '))
                        
                        issues = review_data.get('issues', [])
                        if issues:
                            st.markdown("#### âš ï¸ å‘ç°çš„é—®é¢˜")
                            for issue in issues:
                                st.warning(f"â€¢ {issue}")
                        else:
                            st.success("âœ¨ æœªå‘ç°æ˜æ˜¾é—®é¢˜ï¼")
                
                except json.JSONDecodeError:
                    st.error("âŒ æ— æ³•è§£æ API è¿”å›ç»“æœ")
    
    # åŸåˆ›åº¦æ£€æµ‹ï¼ˆGPT-5.1ï¼‰
    elif originality_button:
        if not problem_text or not problem_text.strip():
            st.error("âš ï¸ è¯·è¾“å…¥é¢˜ç›®å†…å®¹æˆ–ä¸Šä¼ å›¾ç‰‡ï¼")
        else:
            st.markdown("### ğŸ” åŸåˆ›åº¦æ£€æµ‹ç»“æœ")
            
            # ä½¿ç”¨ GPT-5.1 æ£€æµ‹
            gpt_prompt = ORIGINALITY_PROMPT_GPT.format(problem_text=problem_text)
            
            # GPT-5.1 æ£€æµ‹
            with st.spinner("ğŸ” GPT-5.1 æ­£åœ¨æ£€æµ‹åŸåˆ›åº¦..."):
                gpt_result = call_openai_api(gpt_prompt, OPENAI_API_KEY, OPENAI_MODEL)
            
            # æ˜¾ç¤ºç»“æœ
            st.markdown("---")
            st.markdown("### ğŸ“Š åŸåˆ›åº¦æ£€æµ‹ç»“æœ")
            
            try:
                gpt_data = json.loads(gpt_result) if isinstance(gpt_result, str) else gpt_result
                
                if "error" in gpt_data:
                    st.error(f"âŒ GPT-5.1 è°ƒç”¨å¤±è´¥: {gpt_data['error']}")
                else:
                    conclusion = gpt_data.get('originality_conclusion', 'UNKNOWN')
                    st.markdown(f"## {get_originality_emoji(conclusion)} {conclusion}")
                    
                    similar_problems = gpt_data.get('similar_problems', [])
                    if similar_problems:
                        st.markdown("#### ğŸ” å‘ç°çš„ç›¸ä¼¼é¢˜ç›®")
                        for idx, prob in enumerate(similar_problems[:3], 1):
                            with st.expander(f"ç›¸ä¼¼é¢˜ç›® {idx} - ç›¸ä¼¼åº¦: {prob.get('similarity_percentage', 0)}%"):
                                st.markdown(f"**æ¥æº**: {prob.get('source', 'æœªçŸ¥')}")
                                source_url = prob.get('source_url', '')
                                if source_url and source_url.strip():
                                    if source_url.startswith('http'):
                                        st.markdown(f"**é“¾æ¥**: [{source_url}]({source_url})")
                                    else:
                                        st.markdown(f"**è¯¦ç»†å‡ºå¤„**: {source_url}")
                                st.markdown(f"**é¢˜ç›®å†…å®¹**: {prob.get('content', 'æ— ')}")
                                st.markdown(f"**ç›¸ä¼¼åŸå› **: {prob.get('similarity_reason', 'æ— ')}")
                    else:
                        st.success("âœ… æœªå‘ç°é«˜åº¦ç›¸ä¼¼çš„é¢˜ç›®")
                    
                    unique_aspects = gpt_data.get('unique_aspects', [])
                    if unique_aspects:
                        st.markdown("#### âœ¨ é¢˜ç›®çš„ç‹¬ç‰¹ä¹‹å¤„")
                        for aspect in unique_aspects:
                            st.success(f"â€¢ {aspect}")
                    
                    if gpt_data.get('overall_assessment'):
                        st.markdown("---")
                        st.info(f"ğŸ“ **æ•´ä½“è¯„ä¼°**: {gpt_data['overall_assessment']}")
            
            except Exception as e:
                st.error(f"âŒ è§£æç»“æœå¤±è´¥: {e}")
    
    else:
        st.info("""
        ğŸ‘ˆ è¯·åœ¨å·¦ä¾§é€‰æ‹©è¾“å…¥æ–¹å¼ï¼š
        
        **ğŸ’¬ æ–‡å­—è¾“å…¥** - ç›´æ¥è¾“å…¥é¢˜ç›®æ–‡å­—
        
        **ğŸ“· å›¾ç‰‡ä¸Šä¼ ** - ä¸Šä¼ æˆªå›¾æˆ–ç…§ç‰‡
        - ä¸Šä¼ å›¾ç‰‡åç‚¹å‡»"AIè¯†åˆ«"
        - è¯†åˆ«ç»“æœå¯ä»¥ç¼–è¾‘ä¿®æ”¹
        - ç„¶åé€‰æ‹©å®¡æ ¸åŠŸèƒ½
        """)

# åº•éƒ¨è¯´æ˜
st.markdown("---")
st.markdown("""
<div style='text-align: center; color: gray;'>
    <p><strong>æ•°å­¦é¢˜ç›®å®¡æ ¸ç³»ç»Ÿ</strong> - è´¨é‡å®¡æ ¸ä¸åŸåˆ›åº¦æ£€æµ‹</p>
    <p>æ”¯æŒæ–‡å­—è¾“å…¥ + å›¾ç‰‡ä¸Šä¼  | GPT-5.1 + DeepSeek R1 | Mistral Pixtral OCR</p>
</div>
""", unsafe_allow_html=True)

