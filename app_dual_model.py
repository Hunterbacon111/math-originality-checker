#!/usr/bin/env python3
"""
æ•°å­¦é¢˜ç›®è´¨é‡å®¡æ ¸ä¸åŸåˆ›åº¦æ£€æµ‹ç³»ç»Ÿ - åŒæ¨¡å‹ç‰ˆæœ¬
æ”¯æŒ GPT-5.1 å’Œ DeepSeek V3 å¯¹æ¯”
"""
import streamlit as st
import json
import time
import os
from openai import OpenAI

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="æ•°å­¦é¢˜ç›®å®¡æ ¸ç³»ç»Ÿ - åŒæ¨¡å‹",
    page_icon="ğŸ”",
    layout="wide"
)

# API é…ç½®
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
DEEPSEEK_API_KEY = os.getenv("DEEPSEEK_API_KEY")
OPENAI_MODEL = os.getenv("OPENAI_MODEL", "gpt-5.1-chat-latest")
DEEPSEEK_MODEL = "deepseek-chat"

# æ£€æŸ¥é…ç½®
if not OPENAI_API_KEY:
    st.error("âŒ æœªé…ç½® OPENAI_API_KEY")
    st.stop()

if not DEEPSEEK_API_KEY:
    st.warning("âš ï¸ æœªé…ç½® DEEPSEEK_API_KEYï¼Œå°†åªä½¿ç”¨ GPT-5.1")
    DUAL_MODEL_ENABLED = False
else:
    DUAL_MODEL_ENABLED = True

# è´¨é‡å®¡æ ¸ Prompt
REVIEW_PROMPT_TEMPLATE = """You are an expert mathematics educator reviewing problem quality.

**IMPORTANT**: Do NOT attempt to solve the problem or verify if the answer is correct. Focus ONLY on evaluating the problem statement itself.

Evaluate this mathematical problem based on these 5 criteria:
1. **Clarity** (0-2 points): Is the problem statement clear, unambiguous, and easy to understand?
2. **Mathematical Rigor** (0-2 points): Are mathematical notations, symbols, and expressions used correctly and rigorously?
3. **Completeness** (0-2 points): Does the problem provide all necessary information? Are conditions sufficient to solve it?
4. **Solvability** (0-2 points): Does the problem appear to have a well-defined solution (unique or a clear solution set)?
5. **Educational Value** (0-2 points): Is this a meaningful mathematical problem worth studying?

**Problem to Review:**
{problem_text}

**Your Task:**
Evaluate the problem based on the 5 criteria above and respond in JSON format:

{{
  "clarity_score": 0-2,
  "rigor_score": 0-2,
  "completeness_score": 0-2,
  "solvability_score": 0-2,
  "educational_value_score": 0-2,
  "total_score": 0-10,
  "issues": ["list specific issues, if any"],
  "reasoning": "brief explanation of your evaluation",
  "recommendation": "ACCEPT (â‰¥7) / BORDERLINE (5-6) / REJECT (<5)"
}}

**Remember**: Focus on problem quality, NOT answer correctness!
"""

# åŸåˆ›åº¦æ£€æµ‹ Prompt
ORIGINALITY_PROMPT_TEMPLATE = """ä½ ç°åœ¨æ˜¯ä¸€åèµ„æ·±çš„å­¦æœ¯æŸ¥é‡ä¸“å®¶å’Œé«˜çº§æœç´¢å·¥ç¨‹ä¸“å®¶ã€‚

Task: è¯·é’ˆå¯¹æˆ‘æä¾›çš„é¢˜ç›®è¿›è¡Œæ·±åº¦åˆ†æï¼ŒæŸ¥éªŒè¯¥é¢˜ç›®çš„åŸåˆ›åº¦ï¼ˆæ˜¯å¦åœ¨ä½ çš„çŸ¥è¯†åº“ä¸­å­˜åœ¨åŸé¢˜æˆ–é«˜åº¦ç›¸ä¼¼çš„å˜ä½“ï¼‰ã€‚

**é‡è¦è¯´æ˜**ï¼š
- ä¸¥ç¦ç»™å‡ºä»»ä½•è§£é¢˜æ­¥éª¤æˆ–ç­”æ¡ˆ
- ä¸è¦å°è¯•è§£é¢˜
- åªåˆ†æé¢˜ç›®æœ¬èº«çš„åŸåˆ›æ€§

**æ£€ç´¢ç­–ç•¥ (Search Strategy)**:
1. å…³é”®è¯æŠ½æ ·ï¼šæå–é¢˜ç›®çš„æ ¸å¿ƒçŸ¥è¯†ç‚¹ã€ç½•è§æœ¯è¯­å’Œæ•°æ®ç»„åˆ
2. ç»“æ„åŒ–åŒ¹é…ï¼šå¿½ç•¥å…·ä½“çš„æ•°å€¼ï¼Œé‡ç‚¹å…³æ³¨é¢˜ç›®çš„é€»è¾‘ç»“æ„ã€è®¾å®šèƒŒæ™¯å’Œå·²çŸ¥æ¡ä»¶çš„ç»„åˆæ–¹å¼
3. å¤šå¹³å°è¦†ç›–ï¼šåœ¨ä½ çš„çŸ¥è¯†åº“ä¸­æ£€ç´¢åŒ…æ‹¬ä½†ä¸é™äºï¼š
   - ç»å…¸æ•™æï¼ˆå¦‚åŒæµé«˜ç­‰æ•°å­¦ã€æ™®æ—æ–¯é¡¿å¾®ç§¯åˆ†ç­‰ï¼‰
   - æ ‡å‡†é¢˜åº“ï¼ˆé«˜è€ƒçœŸé¢˜ã€è€ƒç ”çœŸé¢˜ã€AMCã€IMO ç­‰ï¼‰
   - çŸ¥åæ•™è‚²å¹³å°å’Œè®ºå›ï¼ˆAOPSã€çŸ¥ä¹ã€ç™¾åº¦æ•™è‚²ã€StackExchangeã€Chegg ç­‰ï¼‰
   - å­¦æœ¯è®ºæ–‡å’Œç«èµ›é¢˜åº“

**åˆ†æè¦æ±‚ (Analysis Requirements)**:
- ä¸ä»…è¦çœ‹è¯­ä¹‰å’Œæ•°å­—ï¼Œè¿˜è¦å…³æ³¨è§£é¢˜è·¯å¾„çš„ç›¸ä¼¼æ€§
- **å¦‚æœå‘ç°ç›¸ä¼¼é¢˜ç›®ï¼Œå¿…é¡»æä¾›å…·ä½“æ¥æºä¿¡æ¯**ï¼š
  - å¦‚æœæ¥è‡ªç½‘ç«™/è®ºå›ï¼Œæä¾›å®Œæ•´çš„URLé“¾æ¥ï¼ˆå¦‚ï¼šhttps://artofproblemsolving.com/community/...ï¼‰
  - å¦‚æœæ¥è‡ªä¹¦ç±/è¯•å·ï¼Œæä¾›è¯¦ç»†å‡ºå¤„ï¼ˆå¦‚ï¼šã€Šé«˜ç­‰æ•°å­¦ã€‹ç¬¬7ç‰ˆ ç¬¬3ç«  ä¾‹é¢˜5.2ï¼‰
  - å¦‚æœæ¥è‡ªç«èµ›ï¼Œæä¾›å¹´ä»½å’Œé¢˜å·ï¼ˆå¦‚ï¼š2018 AMC 12A Problem 15ï¼‰
- åˆ†æé¢˜ç›®çš„ç‹¬ç‰¹ä¹‹å¤„

**é¢˜ç›®å†…å®¹**:
{problem_text}

**è¾“å‡ºæ ¼å¼ (Output Format)**:
è¯·ä»¥ JSON æ ¼å¼è¾“å‡ºï¼ŒåŒ…å«ä»¥ä¸‹å­—æ®µï¼š

{{
  "originality_conclusion": "åŸåˆ› / ç–‘ä¼¼æ¬è¿ / ç»“æ„é›·åŒ",
  "similar_problems": [
    {{
      "source": "æ¥æºåç§°ï¼ˆå¦‚ï¼šAOPSè®ºå›ã€é«˜è€ƒ2018å¹´å…¨å›½å·Iï¼‰",
      "source_url": "å…·ä½“é“¾æ¥æˆ–è¯¦ç»†å‡ºå¤„ï¼ˆå¦‚æœæœ‰ï¼‰",
      "content": "ç›¸ä¼¼é¢˜ç›®çš„ç®€è¦æè¿°",
      "similarity_percentage": 85,
      "similarity_reason": "ç›¸ä¼¼ä¹‹å¤„çš„å…·ä½“è¯´æ˜"
    }}
  ],
  "unique_aspects": ["åˆ—å‡ºé¢˜ç›®çš„ç‹¬ç‰¹ä¹‹å¤„"],
  "keyword_analysis": "å…³é”®è¯å’Œæ ¸å¿ƒæ¦‚å¿µåˆ†æ",
  "structure_analysis": "é¢˜ç›®ç»“æ„å’Œé€»è¾‘æ¡†æ¶åˆ†æ",
  "overall_assessment": "æ•´ä½“è¯„ä¼°è¯´æ˜"
}}

**é‡è¦æé†’**: 
1. å¿…é¡»æä¾›å…·ä½“çš„æ¥æºé“¾æ¥æˆ–è¯¦ç»†å‡ºå¤„
2. ä¸è¦ç»™åŸåˆ›åº¦æ‰“åˆ†
3. ä¸¥ç¦åœ¨ä»»ä½•å­—æ®µä¸­åŒ…å«è§£é¢˜æ­¥éª¤æˆ–ç­”æ¡ˆï¼
"""

def call_openai_api(prompt, api_key, model, base_url="https://api.openai.com/v1"):
    """è°ƒç”¨ APIï¼ˆæ”¯æŒ OpenAI å’Œ DeepSeekï¼‰"""
    try:
        client = OpenAI(api_key=api_key, base_url=base_url)
        response = client.chat.completions.create(
            model=model,
            messages=[{"role": "user", "content": prompt}],
            response_format={"type": "json_object"}
        )
        return response.choices[0].message.content
    except Exception as e:
        return {"error": str(e)}

def get_recommendation_emoji(recommendation):
    """æ ¹æ®æ¨èç»“æœè¿”å›è¡¨æƒ…ç¬¦å·"""
    if "ACCEPT" in recommendation:
        return "âœ…"
    elif "BORDERLINE" in recommendation:
        return "âš ï¸"
    else:
        return "âŒ"

def get_originality_emoji(conclusion):
    """æ ¹æ®åŸåˆ›åº¦ç»“è®ºè¿”å›è¡¨æƒ…ç¬¦å·"""
    if "åŸåˆ›" in conclusion:
        return "âœ…"
    elif "ç»“æ„é›·åŒ" in conclusion:
        return "âš ï¸"
    else:
        return "âŒ"

# ä¸»ç•Œé¢
st.title("ğŸ” æ•°å­¦é¢˜ç›®å®¡æ ¸ç³»ç»Ÿ - åŒæ¨¡å‹ç‰ˆ")
st.markdown("**GPT-5.1 + DeepSeek V3 äº¤å‰éªŒè¯**")
st.markdown("---")

# ä¾§è¾¹æ 
with st.sidebar:
    st.header("âš™ï¸ ç³»ç»Ÿé…ç½®")
    st.info(f"**GPTæ¨¡å‹**: {OPENAI_MODEL}")
    if DUAL_MODEL_ENABLED:
        st.success(f"**DeepSeek**: {DEEPSEEK_MODEL} âœ…")
    else:
        st.warning("**DeepSeek**: æœªé…ç½®")
    
    st.markdown("---")
    st.header("ğŸ“Š åŠŸèƒ½è¯´æ˜")
    st.markdown("""
    ### 1ï¸âƒ£ è´¨é‡å®¡æ ¸
    - æ¸…æ™°åº¦ (0-2åˆ†)
    - æ•°å­¦ä¸¥è°¨æ€§ (0-2åˆ†)
    - å®Œæ•´æ€§ (0-2åˆ†)
    - å¯è§£æ€§ (0-2åˆ†)
    - æ•™è‚²ä»·å€¼ (0-2åˆ†)
    
    ### 2ï¸âƒ£ åŸåˆ›åº¦æ£€æµ‹
    - ğŸ¤– åŒæ¨¡å‹äº¤å‰éªŒè¯
    - ğŸ“Š ç»“æœå¯¹æ¯”åˆ†æ
    - ğŸ” æ¥æºé“¾æ¥è¿½æº¯
    """)

# ä¸»å†…å®¹
col1, col2 = st.columns([1, 1])

with col1:
    st.header("ğŸ“ è¾“å…¥æ•°å­¦é¢˜ç›®")
    
    problem_text = st.text_area(
        "é¢˜ç›®å†…å®¹",
        height=300,
        placeholder="è¯·è¾“å…¥è¦å®¡æ ¸çš„æ•°å­¦é¢˜ç›®..."
    )
    
    st.markdown("---")
    button_col1, button_col2 = st.columns(2)
    
    with button_col1:
        review_button = st.button("ğŸ“Š è´¨é‡å®¡æ ¸", type="primary", use_container_width=True)
    
    with button_col2:
        originality_button = st.button("ğŸ” åŸåˆ›åº¦æ£€æµ‹ï¼ˆåŒæ¨¡å‹ï¼‰", type="secondary", use_container_width=True)

with col2:
    st.header("ğŸ“Š åˆ†æç»“æœ")
    
    # è´¨é‡å®¡æ ¸
    if review_button:
        if not problem_text.strip():
            st.error("âš ï¸ è¯·è¾“å…¥é¢˜ç›®å†…å®¹ï¼")
        else:
            with st.spinner("ğŸ¤” GPT-5.1 æ­£åœ¨åˆ†æé¢˜ç›®è´¨é‡..."):
                prompt = REVIEW_PROMPT_TEMPLATE.format(problem_text=problem_text)
                result = call_openai_api(prompt, OPENAI_API_KEY, OPENAI_MODEL)
                
                try:
                    if isinstance(result, str):
                        review_data = json.loads(result)
                    else:
                        review_data = result
                    
                    if "error" in review_data:
                        st.error(f"âŒ API è°ƒç”¨å¤±è´¥: {review_data['error']}")
                    else:
                        total_score = review_data.get('total_score', 0)
                        recommendation = review_data.get('recommendation', 'UNKNOWN')
                        
                        st.markdown(f"### {get_recommendation_emoji(recommendation)} è´¨é‡å®¡æ ¸ç»“æœ")
                        
                        score_col1, score_col2 = st.columns([1, 2])
                        with score_col1:
                            st.metric("æ€»åˆ†", f"{total_score}/10")
                        with score_col2:
                            st.markdown(f"**æ¨è**: {recommendation}")
                        
                        st.markdown("---")
                        st.markdown("#### ğŸ“ˆ è¯¦ç»†è¯„åˆ†")
                        
                        score_items = [
                            ("æ¸…æ™°åº¦", review_data.get('clarity_score', 0)),
                            ("æ•°å­¦ä¸¥è°¨æ€§", review_data.get('rigor_score', 0)),
                            ("å®Œæ•´æ€§", review_data.get('completeness_score', 0)),
                            ("å¯è§£æ€§", review_data.get('solvability_score', 0)),
                            ("æ•™è‚²ä»·å€¼", review_data.get('educational_value_score', 0))
                        ]
                        
                        for label, score in score_items:
                            progress = score / 2.0
                            st.progress(progress, text=f"{label}: {score}/2")
                        
                        st.markdown("---")
                        st.markdown("#### ğŸ’¡ è¯„å®¡ç†ç”±")
                        st.write(review_data.get('reasoning', 'æ— '))
                        
                        issues = review_data.get('issues', [])
                        if issues:
                            st.markdown("#### âš ï¸ å‘ç°çš„é—®é¢˜")
                            for issue in issues:
                                st.warning(f"â€¢ {issue}")
                        else:
                            st.success("âœ¨ æœªå‘ç°æ˜æ˜¾é—®é¢˜ï¼")
                        
                except json.JSONDecodeError:
                    st.error("âŒ æ— æ³•è§£æ API è¿”å›ç»“æœ")
    
    # åŸåˆ›åº¦æ£€æµ‹ï¼ˆåŒæ¨¡å‹ï¼‰
    elif originality_button:
        if not problem_text.strip():
            st.error("âš ï¸ è¯·è¾“å…¥é¢˜ç›®å†…å®¹ï¼")
        else:
            st.markdown("### ğŸ¤– åŒæ¨¡å‹åŸåˆ›åº¦æ£€æµ‹")
            
            prompt = ORIGINALITY_PROMPT_TEMPLATE.format(problem_text=problem_text)
            
            # GPT-5.1 æ£€æµ‹
            with st.spinner("ğŸ” GPT-5.1 æ­£åœ¨æ£€æµ‹..."):
                gpt_result = call_openai_api(prompt, OPENAI_API_KEY, OPENAI_MODEL)
            
            # DeepSeek æ£€æµ‹
            deepseek_result = None
            if DUAL_MODEL_ENABLED:
                with st.spinner("ğŸ” DeepSeek V3 æ­£åœ¨æ£€æµ‹..."):
                    deepseek_result = call_openai_api(
                        prompt, 
                        DEEPSEEK_API_KEY, 
                        DEEPSEEK_MODEL,
                        base_url="https://api.deepseek.com"
                    )
            
            # æ˜¾ç¤ºç»“æœ
            tab1, tab2, tab3 = st.tabs(["ğŸ“Š å¯¹æ¯”æ€»ç»“", "ğŸ¤– GPT-5.1", "ğŸ¤– DeepSeek V3"])
            
            with tab1:
                st.markdown("#### ğŸ¯ åŒæ¨¡å‹å¯¹æ¯”")
                
                try:
                    gpt_data = json.loads(gpt_result) if isinstance(gpt_result, str) else gpt_result
                    
                    if deepseek_result:
                        ds_data = json.loads(deepseek_result) if isinstance(deepseek_result, str) else deepseek_result
                        
                        # å¯¹æ¯”ç»“è®º
                        gpt_conclusion = gpt_data.get('originality_conclusion', 'UNKNOWN')
                        ds_conclusion = ds_data.get('originality_conclusion', 'UNKNOWN')
                        
                        st.markdown("##### ğŸ” æ£€æµ‹ç»“è®ºå¯¹æ¯”")
                        comp_col1, comp_col2, comp_col3 = st.columns(3)
                        
                        with comp_col1:
                            st.metric("GPT-5.1", gpt_conclusion, 
                                     delta=get_originality_emoji(gpt_conclusion))
                        
                        with comp_col2:
                            st.metric("DeepSeek V3", ds_conclusion,
                                     delta=get_originality_emoji(ds_conclusion))
                        
                        with comp_col3:
                            if gpt_conclusion == ds_conclusion:
                                st.success("âœ… ç»“è®ºä¸€è‡´\né«˜å¯ä¿¡åº¦")
                            else:
                                st.warning("âš ï¸ ç»“è®ºä¸åŒ\néœ€äººå·¥åˆ¤æ–­")
                        
                        st.markdown("---")
                        st.info("ğŸ’¡ **å»ºè®®**: æŸ¥çœ‹å„æ¨¡å‹çš„è¯¦ç»†åˆ†æï¼ˆåˆ‡æ¢åˆ°å¯¹åº”æ ‡ç­¾é¡µï¼‰")
                    
                    else:
                        st.markdown("##### ğŸ” æ£€æµ‹ç»“è®º")
                        conclusion = gpt_data.get('originality_conclusion', 'UNKNOWN')
                        st.metric("GPT-5.1", conclusion, 
                                 delta=get_originality_emoji(conclusion))
                        st.info("ğŸ’¡ é…ç½® DeepSeek API Key åå¯å¯ç”¨åŒæ¨¡å‹å¯¹æ¯”")
                
                except Exception as e:
                    st.error(f"âŒ è§£æç»“æœå¤±è´¥: {e}")
            
            # GPT-5.1 è¯¦ç»†ç»“æœ
            with tab2:
                try:
                    gpt_data = json.loads(gpt_result) if isinstance(gpt_result, str) else gpt_result
                    
                    if "error" in gpt_data:
                        st.error(f"âŒ GPT-5.1 è°ƒç”¨å¤±è´¥: {gpt_data['error']}")
                    else:
                        conclusion = gpt_data.get('originality_conclusion', 'UNKNOWN')
                        st.markdown(f"### {get_originality_emoji(conclusion)} {conclusion}")
                        
                        # ç›¸ä¼¼é¢˜ç›®
                        similar_problems = gpt_data.get('similar_problems', [])
                        if similar_problems:
                            st.markdown("#### ğŸ” å‘ç°çš„ç›¸ä¼¼é¢˜ç›®")
                            for idx, prob in enumerate(similar_problems[:3], 1):
                                with st.expander(f"ç›¸ä¼¼é¢˜ç›® {idx} - ç›¸ä¼¼åº¦: {prob.get('similarity_percentage', 0)}%"):
                                    st.markdown(f"**æ¥æº**: {prob.get('source', 'æœªçŸ¥')}")
                                    source_url = prob.get('source_url', '')
                                    if source_url and source_url.strip():
                                        if source_url.startswith('http'):
                                            st.markdown(f"**é“¾æ¥**: [{source_url}]({source_url})")
                                        else:
                                            st.markdown(f"**è¯¦ç»†å‡ºå¤„**: {source_url}")
                                    st.markdown(f"**é¢˜ç›®å†…å®¹**: {prob.get('content', 'æ— ')}")
                                    st.markdown(f"**ç›¸ä¼¼åŸå› **: {prob.get('similarity_reason', 'æ— ')}")
                        else:
                            st.success("âœ… æœªå‘ç°é«˜åº¦ç›¸ä¼¼çš„é¢˜ç›®")
                        
                        # ç‹¬ç‰¹ä¹‹å¤„
                        unique_aspects = gpt_data.get('unique_aspects', [])
                        if unique_aspects:
                            st.markdown("#### âœ¨ é¢˜ç›®çš„ç‹¬ç‰¹ä¹‹å¤„")
                            for aspect in unique_aspects:
                                st.success(f"â€¢ {aspect}")
                        
                        # åˆ†æ
                        if gpt_data.get('keyword_analysis'):
                            st.markdown("#### ğŸ”‘ å…³é”®è¯åˆ†æ")
                            st.write(gpt_data['keyword_analysis'])
                        
                        if gpt_data.get('structure_analysis'):
                            st.markdown("#### ğŸ—ï¸ ç»“æ„åˆ†æ")
                            st.write(gpt_data['structure_analysis'])
                        
                        if gpt_data.get('overall_assessment'):
                            st.markdown("---")
                            st.info(f"ğŸ“ **æ•´ä½“è¯„ä¼°**: {gpt_data['overall_assessment']}")
                
                except Exception as e:
                    st.error(f"âŒ è§£æ GPT-5.1 ç»“æœå¤±è´¥: {e}")
            
            # DeepSeek è¯¦ç»†ç»“æœ
            with tab3:
                if not DUAL_MODEL_ENABLED:
                    st.warning("âš ï¸ DeepSeek æœªé…ç½®")
                    st.info("è¯·åœ¨ .env æ–‡ä»¶ä¸­æ·»åŠ  DEEPSEEK_API_KEY ä»¥å¯ç”¨åŒæ¨¡å‹å¯¹æ¯”")
                elif not deepseek_result:
                    st.error("âŒ DeepSeek è°ƒç”¨å¤±è´¥")
                else:
                    try:
                        ds_data = json.loads(deepseek_result) if isinstance(deepseek_result, str) else deepseek_result
                        
                        if "error" in ds_data:
                            st.error(f"âŒ DeepSeek è°ƒç”¨å¤±è´¥: {ds_data['error']}")
                        else:
                            conclusion = ds_data.get('originality_conclusion', 'UNKNOWN')
                            st.markdown(f"### {get_originality_emoji(conclusion)} {conclusion}")
                            
                            # ç›¸ä¼¼é¢˜ç›®
                            similar_problems = ds_data.get('similar_problems', [])
                            if similar_problems:
                                st.markdown("#### ğŸ” å‘ç°çš„ç›¸ä¼¼é¢˜ç›®")
                                for idx, prob in enumerate(similar_problems[:3], 1):
                                    with st.expander(f"ç›¸ä¼¼é¢˜ç›® {idx} - ç›¸ä¼¼åº¦: {prob.get('similarity_percentage', 0)}%"):
                                        st.markdown(f"**æ¥æº**: {prob.get('source', 'æœªçŸ¥')}")
                                        source_url = prob.get('source_url', '')
                                        if source_url and source_url.strip():
                                            if source_url.startswith('http'):
                                                st.markdown(f"**é“¾æ¥**: [{source_url}]({source_url})")
                                            else:
                                                st.markdown(f"**è¯¦ç»†å‡ºå¤„**: {source_url}")
                                        st.markdown(f"**é¢˜ç›®å†…å®¹**: {prob.get('content', 'æ— ')}")
                                        st.markdown(f"**ç›¸ä¼¼åŸå› **: {prob.get('similarity_reason', 'æ— ')}")
                            else:
                                st.success("âœ… æœªå‘ç°é«˜åº¦ç›¸ä¼¼çš„é¢˜ç›®")
                            
                            # ç‹¬ç‰¹ä¹‹å¤„
                            unique_aspects = ds_data.get('unique_aspects', [])
                            if unique_aspects:
                                st.markdown("#### âœ¨ é¢˜ç›®çš„ç‹¬ç‰¹ä¹‹å¤„")
                                for aspect in unique_aspects:
                                    st.success(f"â€¢ {aspect}")
                            
                            # åˆ†æ
                            if ds_data.get('keyword_analysis'):
                                st.markdown("#### ğŸ”‘ å…³é”®è¯åˆ†æ")
                                st.write(ds_data['keyword_analysis'])
                            
                            if ds_data.get('structure_analysis'):
                                st.markdown("#### ğŸ—ï¸ ç»“æ„åˆ†æ")
                                st.write(ds_data['structure_analysis'])
                            
                            if ds_data.get('overall_assessment'):
                                st.markdown("---")
                                st.info(f"ğŸ“ **æ•´ä½“è¯„ä¼°**: {ds_data['overall_assessment']}")
                    
                    except Exception as e:
                        st.error(f"âŒ è§£æ DeepSeek ç»“æœå¤±è´¥: {e}")
    
    else:
        st.info("ğŸ‘ˆ è¯·åœ¨å·¦ä¾§è¾“å…¥é¢˜ç›®å¹¶é€‰æ‹©åŠŸèƒ½")

# åº•éƒ¨è¯´æ˜
st.markdown("---")
st.markdown("""
<div style='text-align: center; color: gray;'>
    <p><strong>æ•°å­¦é¢˜ç›®å®¡æ ¸ç³»ç»Ÿ</strong> - åŒæ¨¡å‹äº¤å‰éªŒè¯ç‰ˆæœ¬</p>
    <p>GPT-5.1 + DeepSeek V3 | æ›´å‡†ç¡® | æ›´å¯é </p>
</div>
""", unsafe_allow_html=True)

